{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e2436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import display_image_grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10, ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c1dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ImageFolder(\n",
    "    root=\"../assets/clean_dataset\",\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "dl = DataLoader(\n",
    "    ds, \n",
    "    batch_size=2, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "try:\n",
    "    batch = next(iter(dl))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "ds.transform = resize_transforms\n",
    "\n",
    "images, labels = next(iter(dl))\n",
    "\n",
    "display_image_grid(images, labels, classes=ds.classes, nrow=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4202636",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.zeros(3)\n",
    "std = torch.zeros(3)\n",
    "n_pixels = 0\n",
    "\n",
    "for images, _ in dl:\n",
    "    b, c, h, w = images.shape   # batch size, channels, height, width\n",
    "    n_pixels += b * h * w\n",
    "\n",
    "    mean += images.sum(dim=[0, 2, 3])\n",
    "    std += (images ** 2).sum(dim=[0, 2, 3])\n",
    "\n",
    "mean /= n_pixels\n",
    "std = (std / n_pixels - mean ** 2).sqrt()\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0345d536",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean.tolist(), std=std.tolist())\n",
    "])\n",
    "\n",
    "ds_normalized = ImageFolder(\n",
    "    root=\"../assets/clean_dataset\",\n",
    "    transform=normalize_transforms\n",
    ")\n",
    "\n",
    "dl_normalized = DataLoader(\n",
    "    ds_normalized, \n",
    "    batch_size=10, \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# get a batch from both dataloaders to compare\n",
    "normalized_tensor = next(iter(dl_normalized))[0][0]\n",
    "original_tensor = next(iter(dl))[0][0]\n",
    "\n",
    "print(\"Original tensor:\", original_tensor[:, 0, 0])  # print first pixel values for each channel\n",
    "print(\"Normalized tensor:\", normalized_tensor[:, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72276d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_t = torch.tensor(mean).view(3, 1, 1)\n",
    "std_t = torch.tensor(std).view(3, 1, 1)\n",
    "\n",
    "denormalized_tensor = normalized_tensor * std_t + mean_t\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "\n",
    "axes[0].imshow(original_tensor.permute(1, 2, 0))\n",
    "axes[0].set_title(\"Original (no normalization)\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(denormalized_tensor.permute(1, 2, 0))\n",
    "axes[1].set_title(\"After normalization\\n(denormalized for display)\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ccd89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the standard pre-computed values\n",
    "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
    "cifar10_std  = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=cifar10_mean, std=cifar10_std)\n",
    "])\n",
    "\n",
    "validation_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=cifar10_mean, std=cifar10_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0831bc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CIFAR10(\n",
    "    root=\"../assets/cifar10\", \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=train_transforms\n",
    ")\n",
    "test_dataset = CIFAR10(\n",
    "    root=\"../assets/cifar10\", \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=validation_transforms\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2fcd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_dataloader))\n",
    "images = images * torch.tensor(cifar10_std).view(3, 1, 1) + torch.tensor(cifar10_mean).view(3, 1, 1)\n",
    "images = images.clamp(0, 1)\n",
    "\n",
    "display_image_grid(images, labels, classes=train_dataset.classes, nrow=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-cifar-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
